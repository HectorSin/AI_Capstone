"""
íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ í‰ê°€ í´ë˜ìŠ¤

Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚œì´ë„ë³„ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
"""

import json
import os
from typing import Dict, Any, Optional, List
from datetime import datetime
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate

from .evaluation_criteria import EvaluationCriteria

# config.settingsë¥¼ importí•˜ë ¤ë©´ ìƒëŒ€ ê²½ë¡œ ë˜ëŠ” ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
try:
    from config.settings import AISettings
except ImportError:
    # ìƒëŒ€ ê²½ë¡œë¡œ ì‹œë„
    import sys
    import os
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from config.settings import AISettings


class ScriptEvaluator:
    """íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None, model_name: str = "gemini-1.5-flash"):
        """
        ScriptEvaluator ì´ˆê¸°í™”
        
        Args:
            api_key: Google API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
            model_name: ì‚¬ìš©í•  Gemini ëª¨ë¸ëª…
        """
        self.api_key = api_key or AISettings.GOOGLE_API_KEY
        self.model_name = model_name
        
        if not self.api_key:
            raise ValueError("Google API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.")
        
        # Gemini ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatGoogleGenerativeAI(
            model=self.model_name,
            temperature=0.3,  # í‰ê°€ëŠ” ì¼ê´€ì„±ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ë‚®ì€ temperature
            google_api_key=self.api_key
        )
        
        # JSON íŒŒì„œ ì´ˆê¸°í™”
        self.json_parser = JsonOutputParser()
        
        # í‰ê°€ ê¸°ì¤€ ì´ˆê¸°í™”
        self.criteria = EvaluationCriteria()
    
    def evaluate_single_difficulty(
        self, 
        script_data: Dict[str, Any], 
        difficulty: str
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ë‚œì´ë„ ìŠ¤í¬ë¦½íŠ¸ í‰ê°€
        
        Args:
            script_data: í‰ê°€í•  ìŠ¤í¬ë¦½íŠ¸ ë°ì´í„° (intro, turns, outro í¬í•¨)
            difficulty: í‰ê°€í•  ë‚œì´ë„ (beginner, intermediate, advanced)
        
        Returns:
            Dict[str, Any]: í‰ê°€ ê²°ê³¼
        """
        try:
            # í‰ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt_text = self.criteria.get_evaluation_prompt(script_data, difficulty)
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            prompt = PromptTemplate(
                template="{prompt}",
                input_variables=["prompt"]
            )
            
            # LLM ì²´ì¸ ìƒì„±
            chain = prompt | self.llm
            
            # í‰ê°€ ì‹¤í–‰
            response = chain.invoke({"prompt": prompt_text})
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.content if hasattr(response, "content") else str(response)
            
            # JSON ì¶”ì¶œ ì‹œë„
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
                if "```json" in response_text:
                    json_start = response_text.find("```json") + 7
                    json_end = response_text.find("```", json_start)
                    response_text = response_text[json_start:json_end].strip()
                elif "```" in response_text:
                    json_start = response_text.find("```") + 3
                    json_end = response_text.find("```", json_start)
                    response_text = response_text[json_start:json_end].strip()
                
                evaluation_result = json.loads(response_text)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
                evaluation_result = {
                    "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
                    "raw_response": response_text
                }
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            evaluation_result["evaluated_at"] = datetime.now().isoformat()
            evaluation_result["difficulty"] = difficulty
            evaluation_result["model"] = self.model_name
            
            return {
                "status": "success",
                "data": evaluation_result
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "difficulty": difficulty
            }
    
    def evaluate_all_difficulties(
        self, 
        script_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì„¸ ê°€ì§€ ë‚œì´ë„ ëª¨ë‘ í‰ê°€
        
        Args:
            script_data: ì„¸ ê°€ì§€ ë‚œì´ë„ê°€ ëª¨ë‘ í¬í•¨ëœ ìŠ¤í¬ë¦½íŠ¸ ë°ì´í„°
                {
                    "beginner": {...},
                    "intermediate": {...},
                    "advanced": {...}
                }
        
        Returns:
            Dict[str, Any]: ê° ë‚œì´ë„ë³„ í‰ê°€ ê²°ê³¼
        """
        results = {}
        
        # ê° ë‚œì´ë„ë³„ë¡œ í‰ê°€
        for difficulty in ["beginner", "intermediate", "advanced"]:
            if difficulty in script_data:
                print(f"ğŸ“Š {difficulty} ë‚œì´ë„ í‰ê°€ ì¤‘...")
                results[difficulty] = self.evaluate_single_difficulty(
                    script_data[difficulty], 
                    difficulty
                )
            else:
                results[difficulty] = {
                    "status": "error",
                    "error": f"{difficulty} ë‚œì´ë„ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
                }
        
        return results
    
    def compare_difficulties(
        self, 
        script_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì„¸ ê°€ì§€ ë‚œì´ë„ë¥¼ ë¹„êµ í‰ê°€
        
        Args:
            script_data: ì„¸ ê°€ì§€ ë‚œì´ë„ê°€ ëª¨ë‘ í¬í•¨ëœ ìŠ¤í¬ë¦½íŠ¸ ë°ì´í„°
        
        Returns:
            Dict[str, Any]: ë¹„êµ í‰ê°€ ê²°ê³¼
        """
        try:
            # ë¹„êµ í‰ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt_text = self.criteria.get_comparison_prompt(script_data)
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            prompt = PromptTemplate(
                template="{prompt}",
                input_variables=["prompt"]
            )
            
            # LLM ì²´ì¸ ìƒì„±
            chain = prompt | self.llm
            
            # í‰ê°€ ì‹¤í–‰
            response = chain.invoke({"prompt": prompt_text})
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.content if hasattr(response, "content") else str(response)
            
            # JSON ì¶”ì¶œ ì‹œë„
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                if "```json" in response_text:
                    json_start = response_text.find("```json") + 7
                    json_end = response_text.find("```", json_start)
                    response_text = response_text[json_start:json_end].strip()
                elif "```" in response_text:
                    json_start = response_text.find("```") + 3
                    json_end = response_text.find("```", json_start)
                    response_text = response_text[json_start:json_end].strip()
                
                comparison_result = json.loads(response_text)
            except json.JSONDecodeError:
                comparison_result = {
                    "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
                    "raw_response": response_text
                }
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            comparison_result["evaluated_at"] = datetime.now().isoformat()
            comparison_result["model"] = self.model_name
            
            return {
                "status": "success",
                "data": comparison_result
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
    
    def find_script_files(
        self, 
        base_path: str = "/app/podcasts",
        podcast_id: Optional[str] = None
    ) -> List[str]:
        """
        ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ëŠ” ë©”ì„œë“œ
        
        Args:
            base_path: íŒŸìºìŠ¤íŠ¸ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ (Back ì„œë¹„ìŠ¤: /app/podcasts, ë¡œì»¬: ìƒëŒ€ ê²½ë¡œ)
            podcast_id: íŠ¹ì • íŒŸìºìŠ¤íŠ¸ ID (Noneì´ë©´ ëª¨ë“  íŒŸìºìŠ¤íŠ¸ ê²€ìƒ‰)
        
        Returns:
            List[str]: ì°¾ì€ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        script_files = []
        
        try:
            if podcast_id:
                # íŠ¹ì • íŒŸìºìŠ¤íŠ¸ IDì˜ ìŠ¤í¬ë¦½íŠ¸ë§Œ ì°¾ê¸°
                scripts_dir = os.path.join(base_path, podcast_id, "04_scripts")
                if os.path.exists(scripts_dir):
                    for filename in os.listdir(scripts_dir):
                        if filename.startswith("script_") and filename.endswith(".json"):
                            script_files.append(os.path.join(scripts_dir, filename))
            else:
                # ëª¨ë“  íŒŸìºìŠ¤íŠ¸ì˜ ìŠ¤í¬ë¦½íŠ¸ ì°¾ê¸°
                if os.path.exists(base_path):
                    for podcast_dir in os.listdir(base_path):
                        podcast_path = os.path.join(base_path, podcast_dir)
                        if os.path.isdir(podcast_path):
                            scripts_dir = os.path.join(podcast_path, "04_scripts")
                            if os.path.exists(scripts_dir):
                                for filename in os.listdir(scripts_dir):
                                    if filename.startswith("script_") and filename.endswith(".json"):
                                        script_files.append(os.path.join(scripts_dir, filename))
            
            # ê²½ë¡œ ì •ë ¬ (ìµœì‹  íŒŒì¼ ë¨¼ì €)
            script_files.sort(reverse=True)
            
        except Exception as e:
            print(f"âš ï¸ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return script_files
    
    def evaluate_from_file(
        self, 
        file_path: str, 
        compare: bool = True
    ) -> Dict[str, Any]:
        """
        JSON íŒŒì¼ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì½ì–´ì„œ í‰ê°€
        
        Args:
            file_path: JSON íŒŒì¼ ê²½ë¡œ
            compare: Trueë©´ ë¹„êµ í‰ê°€ë„ ìˆ˜í–‰
        
        Returns:
            Dict[str, Any]: í‰ê°€ ê²°ê³¼
        """
        try:
            # JSON íŒŒì¼ ì½ê¸°
            with open(file_path, 'r', encoding='utf-8') as f:
                script_data = json.load(f)
            
            # ê°œë³„ í‰ê°€
            individual_results = self.evaluate_all_difficulties(script_data)
            
            result = {
                "file_path": file_path,
                "individual_evaluations": individual_results
            }
            
            # ë¹„êµ í‰ê°€
            if compare:
                print("ğŸ“Š ë‚œì´ë„ ê°„ ë¹„êµ í‰ê°€ ì¤‘...")
                comparison_result = self.compare_difficulties(script_data)
                result["comparison"] = comparison_result
            
            return {
                "status": "success",
                "data": result
            }
            
        except FileNotFoundError:
            return {
                "status": "error",
                "error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"
            }
        except json.JSONDecodeError as e:
            return {
                "status": "error",
                "error": f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
    
    def evaluate_from_podcast_service(
        self,
        base_path: str = "/app/podcasts",
        podcast_id: Optional[str] = None,
        script_index: Optional[int] = None,
        compare: bool = True
    ) -> Dict[str, Any]:
        """
        Back ì„œë¹„ìŠ¤ì—ì„œ ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì•„ì„œ í‰ê°€
        
        Args:
            base_path: íŒŸìºìŠ¤íŠ¸ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ
            podcast_id: íŠ¹ì • íŒŸìºìŠ¤íŠ¸ ID (Noneì´ë©´ ìµœì‹  íŒŸìºìŠ¤íŠ¸ ì‚¬ìš©)
            script_index: íŠ¹ì • ìŠ¤í¬ë¦½íŠ¸ ì¸ë±ìŠ¤ (Noneì´ë©´ ì²« ë²ˆì§¸ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©)
            compare: Trueë©´ ë¹„êµ í‰ê°€ë„ ìˆ˜í–‰
        
        Returns:
            Dict[str, Any]: í‰ê°€ ê²°ê³¼
        """
        try:
            # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì°¾ê¸°
            if podcast_id and script_index is not None:
                # íŠ¹ì • íŒŒì¼ ê²½ë¡œ êµ¬ì„±
                file_path = os.path.join(base_path, podcast_id, "04_scripts", f"script_{script_index}.json")
                if not os.path.exists(file_path):
                    return {
                        "status": "error",
                        "error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"
                    }
                script_files = [file_path]
            else:
                # ìë™ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸°
                script_files = self.find_script_files(base_path, podcast_id)
                if not script_files:
                    return {
                        "status": "error",
                        "error": f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {base_path}"
                    }
            
            # ì²« ë²ˆì§¸ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì‚¬ìš©
            file_path = script_files[0]
            print(f"ğŸ“‚ í‰ê°€í•  íŒŒì¼: {file_path}")
            
            # íŒŒì¼ì—ì„œ í‰ê°€
            return self.evaluate_from_file(file_path, compare)
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
    
    def save_evaluation_result(
        self, 
        evaluation_result: Dict[str, Any], 
        output_dir: str = "data/output/evaluations"
    ) -> Optional[str]:
        """
        í‰ê°€ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            evaluation_result: í‰ê°€ ê²°ê³¼
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
        Returns:
            Optional[str]: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(output_dir, exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"evaluation_{timestamp}.json"
            filepath = os.path.join(output_dir, filename)
            
            # íŒŒì¼ ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(evaluation_result, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… í‰ê°€ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"âŒ í‰ê°€ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def print_evaluation_summary(self, evaluation_result: Dict[str, Any]):
        """
        í‰ê°€ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        
        Args:
            evaluation_result: í‰ê°€ ê²°ê³¼
        """
        if evaluation_result.get("status") != "success":
            print(f"âŒ í‰ê°€ ì‹¤íŒ¨: {evaluation_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            return
        
        data = evaluation_result.get("data", {})
        individual = data.get("individual_evaluations", {})
        
        print("\n" + "="*60)
        print("ğŸ“Š íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ í‰ê°€ ê²°ê³¼")
        print("="*60)
        
        # ê° ë‚œì´ë„ë³„ í‰ê°€ ê²°ê³¼
        for difficulty in ["beginner", "intermediate", "advanced"]:
            if difficulty in individual:
                result = individual[difficulty]
                if result.get("status") == "success":
                    eval_data = result.get("data", {})
                    score = eval_data.get("overall_score", "N/A")
                    is_appropriate = eval_data.get("is_appropriate", False)
                    status_icon = "âœ…" if is_appropriate else "âš ï¸"
                    
                    print(f"\n{difficulty.upper()} ë‚œì´ë„:")
                    print(f"  {status_icon} ì¢…í•© ì ìˆ˜: {score}/10")
                    print(f"  ì í•©ì„±: {'ì í•©' if is_appropriate else 'ë¶€ì í•©'}")
                    
                    scores = eval_data.get("scores", {})
                    if scores:
                        print(f"  - ë‚œì´ë„ ì í•©ì„±: {scores.get('difficulty_appropriateness', 'N/A')}/10")
                        print(f"  - ìš©ì–´ ì‚¬ìš©: {scores.get('terminology_usage', 'N/A')}/10")
                        print(f"  - ì„¤ëª… ëª…í™•ì„±: {scores.get('clarity_of_explanation', 'N/A')}/10")
                        print(f"  - í†¤ê³¼ ìŠ¤íƒ€ì¼: {scores.get('tone_and_style', 'N/A')}/10")
                        print(f"  - êµ¬ì¡°ì™€ íë¦„: {scores.get('structure_and_flow', 'N/A')}/10")
                else:
                    print(f"\n{difficulty.upper()} ë‚œì´ë„: âŒ í‰ê°€ ì‹¤íŒ¨ - {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        # ë¹„êµ í‰ê°€ ê²°ê³¼
        comparison = data.get("comparison", {})
        if comparison.get("status") == "success":
            comp_data = comparison.get("data", {})
            print(f"\nğŸ“ˆ ë‚œì´ë„ ê°„ ë¹„êµ:")
            print(f"  - ë‚œì´ë„ êµ¬ë¶„: {comp_data.get('comparison', {}).get('difficulty_distinction', 'N/A')}/10")
            print(f"  - ì „ì²´ ê· í˜•: {comp_data.get('comparison', {}).get('overall_balance', 'N/A')}/10")
        
        print("\n" + "="*60)

